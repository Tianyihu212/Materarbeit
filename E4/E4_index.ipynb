{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "613cb897",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "import glob\n",
    "\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import boto3\n",
    "import cv2\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8375028b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GLDV2(Dataset):\n",
    "\n",
    "    def __init__(self, stage: str, inferance=True):\n",
    "        self.stage = stage\n",
    "        self.df = read_csv(stage)\n",
    "        self.df.drop(self.df.filter(regex=\"Unname\"), axis=1, inplace=True)\n",
    "        self.label_list = self.df.landmark_id.tolist()\n",
    "        self.namelist = [i.split('\\\\')[-1] for i in self.df.anchor.tolist()]\n",
    "        print(f'shape of df is {len(self.df)}, stage is {stage}')\n",
    "        self.s3path = 'Your data set path'\n",
    "        self.my_transformer = transforms.Compose([\n",
    "          transforms.Resize((224,224)),\n",
    "          transforms.ToTensor(),\n",
    "          transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        label = self.df.iloc[index]['landmark_id']\n",
    "        name = self.namelist[index]\n",
    "        anchor = self.df.iloc[index]['anchor'].split('\\\\')\n",
    "        anchor_class = anchor[1]\n",
    "        anchor_filen = anchor[2].split('.')[0].lower()\n",
    "        if self.stage == 'index':     \n",
    "            anchor_image = '/home/bo/work/tianyi/dataset_original/train/' + name[0] +'/' + name[1] +'/' + name[2] +'/' +anchor_filen+'.jpg'\n",
    "        else:\n",
    "            anchor_image = '/home/bo/work/tianyi/dataset_original/test/' + anchor_filen+'.jpg'\n",
    "        anchor_im = Image.open(anchor_image).convert('RGB')\n",
    "#         anchor_im = cv2.imread(anchor_image)\n",
    "#         anchor_im = cv2.cvtColor(anchor_im, cv2.COLOR_BGR2RGB)\n",
    "        transformed_anchor_im = self.my_transformer(anchor_im)\n",
    "        return transformed_anchor_im \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "\n",
    "def read_csv(stage):\n",
    "\n",
    "    if stage == 'public':\n",
    "        df = pd.read_csv('Your public csv path')\n",
    "    elif stage == 'private':\n",
    "        df = pd.read_csv('Your private csv path')\n",
    "    elif stage == 'public_private':\n",
    "        df = pd.read_csv('Your public_private csv path')\n",
    "    elif stage == 'index':\n",
    "        df = pd.read_csv('Your index csv path')\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f'not supported stage{stage}')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db41738e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of df is 1000, stage is public_private\n",
      "shape of df is 100000, stage is index\n",
      "Loaded pretrained weights for efficientnet-b0\n",
      "current batch is 0 at test\n",
      "(500, 1280, 7, 7)\n",
      "current batch is 1 at test\n",
      "(500, 1280, 7, 7)\n"
     ]
    }
   ],
   "source": [
    "def extract_global_features(model, dataloader, stage = 'index'):\n",
    "    with torch.inference_mode():\n",
    "        BATCH_IDX = 0\n",
    "        for batch_idx, batch_img in enumerate(dataloader):\n",
    "            print(f'current batch is {batch_idx} at {stage}')\n",
    "            embed = model.extract_features(batch_img.to(device))\n",
    "            embed = embed.cpu().detach().numpy()\n",
    "            print(embed.shape)\n",
    "            # embed = embed.reshape(500,1280,7,7)\n",
    "            embed_np = np.mean(embed,axis=(2,3))\n",
    "            with open(SAVE_PATH + stage + '/' + str(BATCH_IDX).zfill(3) + '.npy', 'wb') as f:\n",
    "                np.save(f, np.array(embed_np))\n",
    "            BATCH_IDX += 1\n",
    "\n",
    "\n",
    "SAVE_PATH = 'out/'\n",
    "\n",
    "device = 'cuda'\n",
    "\n",
    "query_dataset = GLDV2('public_private')\n",
    "index_dataset = GLDV2('index')\n",
    "\n",
    "query_dataloader = DataLoader(query_dataset, batch_size=500, shuffle=False)\n",
    "index_dataloader = DataLoader(index_dataset, batch_size=500, shuffle=False)\n",
    "\n",
    "\n",
    "embed_model = EfficientNet.from_pretrained('efficientnet-b0',num_classes=10)\n",
    "model_path = 'model path'\n",
    "model_state = torch.load(model_path)['model']\n",
    "embed_model.load_state_dict(model_state)\n",
    "embed_model.cuda()\n",
    "\n",
    "embed_model.eval()\n",
    "# extract_global_features(embed_model, index_dataloader, 'index')\n",
    "extract_global_features(embed_model, query_dataloader, 'test')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
