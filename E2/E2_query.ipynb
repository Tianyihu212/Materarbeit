{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f64e1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "import glob\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "torch.cuda.empty_cache()\n",
    "import boto3\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4e95fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['AWS_ACCESS_KEY_ID'] = 'AWS_ACCESS_KEY_ID'\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = 'AWS_SECRET_ACCESS_KEY'\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "\n",
    "def read_image_from_s3(key):\n",
    "    bucket = s3.Bucket('s3 path')\n",
    "    img = bucket.Object(key).get().get('Body').read()\n",
    "    img = cv2.imdecode(np.asarray(bytearray(img)), cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c10a39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_from_s3(stage):\n",
    "\n",
    "    if stage == 'public':\n",
    "        df = pd.read_csv('Your public csv path')\n",
    "    elif stage == 'private':\n",
    "        df = pd.read_csv('Your private csv path')\n",
    "    elif stage == 'public_private':\n",
    "        df = pd.read_csv('Your public_private csv path')\n",
    "    elif stage == 'index':\n",
    "        df = pd.read_csv('Your index csv path')\n",
    "        \n",
    "\n",
    "    else:\n",
    "        raise ValueError(f'not supported stage{stage}')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7011227",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseGLDV2(Dataset):\n",
    "\n",
    "    def __init__(self, stage: str, inferance=True):\n",
    "\n",
    "        self.df = read_csv_from_s3(stage)\n",
    "        self.df.drop(self.df.filter(regex=\"Unname\"), axis=1, inplace=True)\n",
    "        self.label_list = self.df.landmark_id.tolist()\n",
    "        self.namelist = [i.split('\\\\')[-1] for i in self.df.anchor.tolist()]\n",
    "        print(f'shape of df is {len(self.df)}, stage is {stage}')\n",
    "        self.s3 = boto3.resource('s3')\n",
    "        if stage == 'index':\n",
    "            self.s3path = 'data/train/train_compress'\n",
    "        else:\n",
    "            self.s3path = 'data/test'\n",
    "        self.my_transformer = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        label = self.df.iloc[index]['landmark_id']\n",
    "        anchor = self.df.iloc[index]['anchor'].split('\\\\')\n",
    "        anchor_class = anchor[1]\n",
    "        anchor_filen = anchor[2]\n",
    "        anchor_image = self.s3path + '/' + anchor_class + '/' + anchor_filen\n",
    "        try:\n",
    "            anchor_im = read_image_from_s3(anchor_image)\n",
    "        except:\n",
    "            anchor_im = []\n",
    "            print(f'Error by {anchor_image}')\n",
    "        transformed_anchor_im = self.my_transformer(anchor_im)\n",
    "        return label, transformed_anchor_im , anchor_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26b2279a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_at_k(y_true, y_denominator, y_pred):\n",
    "    assert isinstance(y_true, np.ndarray) and isinstance(y_pred, np.ndarray)\n",
    "    assert y_true.ndim == 2 and y_pred.ndim == 2\n",
    "\n",
    "    k = y_pred.shape[1]\n",
    "    is_correct_list = []\n",
    "\n",
    "    for i in range(y_true.shape[1]):\n",
    "        is_correct = y_true[:, i][:, np.newaxis] == y_pred\n",
    "        is_correct_list.append(is_correct)\n",
    "    is_correct_mat = np.logical_or.reduce(np.array(is_correct_list))\n",
    "\n",
    "    cumsum_mat = np.apply_along_axis(np.cumsum, axis=1, arr=is_correct_mat)\n",
    "    arange_mat = np.expand_dims(np.arange(1, k + 1), axis=0)\n",
    "    ap_100_list = np.sum((cumsum_mat / arange_mat) * is_correct_mat, axis=1) / y_denominator\n",
    "    ap_100_list[ap_100_list>1]=1\n",
    "\n",
    "    return np.mean(ap_100_list), ap_100_list\n",
    "\n",
    "def list_to_array (x):\n",
    "    dff = pd.concat([pd.DataFrame({'{}'.format(index):labels}) for index,labels in enumerate(string_to_list(x))],axis=1)\n",
    "    return dff.fillna(0).values.T.astype(int)\n",
    "\n",
    "def string_to_list(x):\n",
    "    res = []\n",
    "    for a in x:\n",
    "        tmp = a.split(' ')\n",
    "        tmp2= [int(i) for i in tmp]\n",
    "        res.append(tmp2)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb15a215",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 500\n",
    "class NN:\n",
    "    def __init__(self, batch_size=BATCH_SIZE, dim=512):\n",
    "        self.array = np.empty((0, dim))\n",
    "        self.id = []\n",
    "        self.score = np.empty((0, batch_size))\n",
    "\n",
    "    def add_item(self, item):\n",
    "        if item.ndim == 1:\n",
    "            item = item[np.newaxis, :]\n",
    "        self.array = item\n",
    "\n",
    "    def search(self, search_item, top_k=100):\n",
    "        self.res = cosine_similarity(self.array, search_item)\n",
    "        self.score = np.concatenate((self.score, self.res), axis=0)\n",
    "        self.rank = self.res[:, 0].argsort()[::-1][:top_k]\n",
    "\n",
    "    def update(self):\n",
    "        self.array = np.array([self.array[i] for i in self.rank])\n",
    "        self.id = [self.id[i] for i in self.rank]\n",
    "\n",
    "    def get_top_k(self, top_k=100):\n",
    "        return np.argsort(-self.score, axis=0)[:top_k, :]\n",
    "\n",
    "def index_to_label(index_array, label_list):\n",
    "    res = []\n",
    "    for i in range(len(index_array)):\n",
    "        res.append(label_list[index_array[i].astype(int)])\n",
    "    return np.array(res)\n",
    "\n",
    "def comt_denominater(y_true, index_label_list):\n",
    "    res = []\n",
    "    for i in y_true:\n",
    "        count = 0\n",
    "        for j in i:\n",
    "            count += index_label_list.count(j)\n",
    "        res.append(count)\n",
    "    res = np.array(res)\n",
    "    res[res > 50] = 50\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc11063f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of df is 100000, stage is index\n",
      "shape of df is 650, stage is private\n"
     ]
    }
   ],
   "source": [
    "index_dataset = SiameseGLDV2('index')\n",
    "test_dataset = SiameseGLDV2('private')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274f0fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "7it [00:00, 63.31it/s]\u001b[A\n",
      "14it [00:00, 48.42it/s]\u001b[A\n",
      "20it [00:00, 38.21it/s]\u001b[A\n",
      "25it [00:00, 31.91it/s]\u001b[A\n",
      "29it [00:00, 27.75it/s]\u001b[A\n",
      "32it [00:01, 25.07it/s]\u001b[A\n",
      "35it [00:01, 22.70it/s]\u001b[A\n",
      "38it [00:01, 20.62it/s]\u001b[A\n",
      "41it [00:01, 18.90it/s]\u001b[A\n",
      "43it [00:01, 17.88it/s]\u001b[A\n",
      "45it [00:01, 16.91it/s]\u001b[A\n",
      "47it [00:02, 15.95it/s]\u001b[A\n",
      "49it [00:02, 15.17it/s]\u001b[A\n",
      "51it [00:02, 14.49it/s]\u001b[A\n",
      "53it [00:02, 13.78it/s]\u001b[A\n",
      "55it [00:02, 13.23it/s]\u001b[A\n",
      "57it [00:02, 12.77it/s]\u001b[A\n",
      "59it [00:02, 12.25it/s]\u001b[A\n",
      "61it [00:03, 11.90it/s]\u001b[A\n",
      "63it [00:03, 11.57it/s]\u001b[A\n",
      "65it [00:03, 11.16it/s]\u001b[A\n",
      "67it [00:03, 10.82it/s]\u001b[A\n",
      "69it [00:03, 10.53it/s]\u001b[A\n",
      "71it [00:04, 10.22it/s]\u001b[A\n",
      "73it [00:04,  9.99it/s]\u001b[A\n",
      "75it [00:04,  9.74it/s]\u001b[A\n",
      "76it [00:04,  9.58it/s]\u001b[A\n",
      "77it [00:04,  9.41it/s]\u001b[A\n",
      "78it [00:04,  9.35it/s]\u001b[A\n",
      "79it [00:05,  9.16it/s]\u001b[A\n",
      "80it [00:05,  9.02it/s]\u001b[A\n",
      "81it [00:05,  8.92it/s]\u001b[A\n",
      "82it [00:05,  8.78it/s]\u001b[A\n",
      "83it [00:05,  8.70it/s]\u001b[A\n",
      "84it [00:05,  8.68it/s]\u001b[A\n",
      "85it [00:05,  8.56it/s]\u001b[A\n",
      "86it [00:05,  8.47it/s]\u001b[A\n",
      "87it [00:05,  8.45it/s]\u001b[A\n",
      "88it [00:06,  8.36it/s]\u001b[A\n",
      "89it [00:06,  8.29it/s]\u001b[A\n",
      "90it [00:06,  8.26it/s]\u001b[A\n",
      "91it [00:06,  8.18it/s]\u001b[A\n",
      "92it [00:06,  8.11it/s]\u001b[A\n",
      "93it [00:06,  8.10it/s]\u001b[A\n",
      "94it [00:06,  8.03it/s]\u001b[A\n",
      "95it [00:06,  7.94it/s]\u001b[A\n",
      "96it [00:07,  7.92it/s]\u001b[A\n",
      "97it [00:07,  7.85it/s]\u001b[A\n",
      "98it [00:07,  7.78it/s]\u001b[A\n",
      "99it [00:07,  7.77it/s]\u001b[A\n",
      "100it [00:07,  7.68it/s]\u001b[A\n",
      "101it [00:07,  7.63it/s]\u001b[A\n",
      "102it [00:07,  7.63it/s]\u001b[A\n",
      "103it [00:08,  7.56it/s]\u001b[A\n",
      "104it [00:08,  7.50it/s]\u001b[A\n",
      "105it [00:08,  7.49it/s]\u001b[A\n",
      "106it [00:08,  7.42it/s]\u001b[A\n",
      "107it [00:08,  7.36it/s]\u001b[A\n",
      "108it [00:08,  7.36it/s]\u001b[A\n",
      "109it [00:08,  7.30it/s]\u001b[A\n",
      "110it [00:08,  7.25it/s]\u001b[A\n",
      "111it [00:09,  7.25it/s]\u001b[A\n",
      "112it [00:09,  7.19it/s]\u001b[A\n",
      "113it [00:09,  7.14it/s]\u001b[A\n",
      "114it [00:09,  7.13it/s]\u001b[A\n",
      "115it [00:09,  7.07it/s]\u001b[A\n",
      "116it [00:09,  7.01it/s]\u001b[A\n",
      "117it [00:09,  7.00it/s]\u001b[A\n",
      "118it [00:10,  6.95it/s]\u001b[A\n",
      "119it [00:10,  6.89it/s]\u001b[A\n",
      "120it [00:10,  6.88it/s]\u001b[A\n",
      "121it [00:10,  6.82it/s]\u001b[A\n",
      "122it [00:10,  6.77it/s]\u001b[A\n",
      "123it [00:10,  6.72it/s]\u001b[A\n",
      "124it [00:11,  6.67it/s]\u001b[A\n",
      "125it [00:11,  6.63it/s]\u001b[A\n",
      "126it [00:11,  6.62it/s]\u001b[A\n",
      "127it [00:11,  6.57it/s]\u001b[A\n",
      "128it [00:11,  6.54it/s]\u001b[A\n",
      "129it [00:11,  6.54it/s]\u001b[A\n",
      "130it [00:11,  6.48it/s]\u001b[A\n",
      "131it [00:12,  6.43it/s]\u001b[A\n",
      "132it [00:12,  6.42it/s]\u001b[A\n",
      "133it [00:12,  6.37it/s]\u001b[A\n",
      "134it [00:12,  6.33it/s]\u001b[A\n",
      "135it [00:12,  6.32it/s]\u001b[A\n",
      "136it [00:12,  6.27it/s]\u001b[A\n",
      "137it [00:13,  6.22it/s]\u001b[A\n",
      "138it [00:13,  6.21it/s]\u001b[A\n",
      "139it [00:13,  6.16it/s]\u001b[A\n",
      "140it [00:13,  6.11it/s]\u001b[A\n",
      "141it [00:13,  6.10it/s]\u001b[A\n",
      "142it [00:13,  6.06it/s]\u001b[A\n",
      "143it [00:14,  6.03it/s]\u001b[A\n",
      "144it [00:14,  6.02it/s]\u001b[A\n",
      "145it [00:14,  5.98it/s]\u001b[A\n",
      "146it [00:14,  5.95it/s]\u001b[A\n",
      "147it [00:14,  5.94it/s]\u001b[A\n",
      "148it [00:14,  5.90it/s]\u001b[A\n",
      "149it [00:15,  5.86it/s]\u001b[A\n",
      "150it [00:15,  5.85it/s]\u001b[A\n",
      "151it [00:15,  5.81it/s]\u001b[A\n",
      "152it [00:15,  5.77it/s]\u001b[A\n",
      "153it [00:15,  5.75it/s]\u001b[A\n",
      "154it [00:15,  5.71it/s]\u001b[A\n",
      "155it [00:16,  5.68it/s]\u001b[A\n",
      "156it [00:16,  5.67it/s]\u001b[A\n",
      "157it [00:16,  5.63it/s]\u001b[A\n",
      "158it [00:16,  5.60it/s]\u001b[A\n",
      "159it [00:16,  5.59it/s]\u001b[A\n",
      "160it [00:17,  5.56it/s]\u001b[A\n",
      "161it [00:17,  5.52it/s]\u001b[A\n",
      "162it [00:17,  5.51it/s]\u001b[A\n",
      "163it [00:17,  5.47it/s]\u001b[A\n",
      "164it [00:17,  5.44it/s]\u001b[A\n",
      "165it [00:17,  5.44it/s]\u001b[A\n",
      "166it [00:18,  5.40it/s]\u001b[A\n",
      "167it [00:18,  5.37it/s]\u001b[A\n",
      "168it [00:18,  5.36it/s]\u001b[A\n",
      "169it [00:18,  5.33it/s]\u001b[A\n",
      "170it [00:18,  5.30it/s]\u001b[A\n",
      "171it [00:19,  5.30it/s]\u001b[A\n",
      "172it [00:19,  5.26it/s]\u001b[A\n",
      "173it [00:19,  5.23it/s]\u001b[A\n",
      "174it [00:19,  5.22it/s]\u001b[A\n",
      "175it [00:19,  5.18it/s]\u001b[A\n",
      "176it [00:20,  5.14it/s]\u001b[A\n",
      "177it [00:20,  5.14it/s]\u001b[A\n",
      "178it [00:20,  5.11it/s]\u001b[A\n",
      "179it [00:20,  5.08it/s]\u001b[A\n",
      "180it [00:20,  5.07it/s]\u001b[A\n",
      "181it [00:21,  5.05it/s]\u001b[A\n",
      "182it [00:21,  5.01it/s]\u001b[A\n",
      "183it [00:21,  5.01it/s]\u001b[A\n",
      "184it [00:21,  4.97it/s]\u001b[A\n",
      "185it [00:21,  4.94it/s]\u001b[A\n",
      "186it [00:22,  4.93it/s]\u001b[A\n",
      "187it [00:22,  4.90it/s]\u001b[A\n",
      "188it [00:22,  4.88it/s]\u001b[A\n",
      "189it [00:22,  4.88it/s]\u001b[A\n",
      "190it [00:22,  4.85it/s]\u001b[A\n",
      "191it [00:23,  4.83it/s]\u001b[A\n",
      "192it [00:23,  4.83it/s]\u001b[A\n",
      "193it [00:23,  4.80it/s]\u001b[A\n",
      "194it [00:23,  4.78it/s]\u001b[A\n",
      "195it [00:23,  4.77it/s]\u001b[A\n",
      "196it [00:24,  4.75it/s]\u001b[A\n",
      "197it [00:24,  4.72it/s]\u001b[A\n",
      "198it [00:24,  4.72it/s]\u001b[A\n",
      "199it [00:24,  4.69it/s]\u001b[A\n",
      "200it [00:25,  7.99it/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "npy_list_index = sorted(glob.glob('out/index/*.npy'))\n",
    "npy_list_test = sorted(glob.glob('out/test/*.npy'))\n",
    "images = []\n",
    "score_list = []\n",
    "ranked_list = []\n",
    "aps = []\n",
    "\n",
    "for ind,npy_test_path in tqdm(enumerate(npy_list_test)):\n",
    "    \n",
    "    npy_test = np.load(npy_test_path)\n",
    "    indexer = NN(dim=1000, batch_size=npy_test.shape[0])\n",
    "    for i,npy_index_path in tqdm(enumerate(npy_list_index)):\n",
    "        npy_index = np.load(npy_index_path)\n",
    "        indexer.add_item(npy_index)\n",
    "        indexes = indexer.search(npy_test)\n",
    "    top_k_array = indexer.get_top_k()\n",
    "    ranked_list.append(top_k_array)\n",
    "    y_true = list_to_array(test_dataset.label_list[ind*BATCH_SIZE:min((ind+1)*BATCH_SIZE, len(test_dataset.label_list))])\n",
    "    map_100,ap_list = map_at_k(y_true= y_true,\n",
    "             y_denominator= comt_denominater(y_true, index_dataset.label_list),\n",
    "             y_pred= index_to_label(top_k_array.T,np.array(index_dataset.label_list)))\n",
    "    aps.extend(ap_list)\n",
    "    score_list.extend(list(np.sort(indexer.score, axis=0)[-1,:]))\n",
    "ranked_list = np.hstack(ranked_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c8a424",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The map@100 is : {}'.format(np.mean(aps)))\n",
    "print('The max ap@100 is : {}'.format(np.max(aps)))\n",
    "print('The min ap@100 is : {}'.format(np.min(aps)))\n",
    "print('The max cos similarity is : {}'.format(max(score_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9385337b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_query_and_top_k_match(query_dataset, index_dataset, ranked_list, index, k=24, width=5):\n",
    "    row = int((k+1)//width)\n",
    "    k = row * width -1\n",
    "    images = []\n",
    "    top_k_indices = ranked_list[:,index]\n",
    "    top_k_index = top_k_indices[:k]\n",
    "    label, _, query_img_path = query_dataset[index]\n",
    "    fig = plt.figure(figsize=(10, row*3.3))\n",
    "    a = plt.subplot(row, width, 1)\n",
    "    plt.subplots_adjust(left=0.1, bottom = 0.1, right = 0.95, wspace = 0.1, hspace=0, top = 0.7)\n",
    "    plt.imshow(query_img_path)\n",
    "    a.set_title(f'Query image: {label}')\n",
    "    a.set_xticks([])\n",
    "    a.set_yticks([])\n",
    "    \n",
    "    for i in range(1,k+1):\n",
    "        label, _, index_img_path = index_dataset[top_k_index[i-1]]\n",
    "        a = plt.subplot(row, width, i+1)\n",
    "        plt.imshow(index_img_path)\n",
    "        a.set_title(f'top{i}:{label}')\n",
    "        a.set_xticks([])\n",
    "        a.set_yticks([])\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeec74aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_query_and_top_k_match(test_dataset, index_dataset, ranked_list, 0, k=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727d3fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ap_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7247d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_query_and_top_k_match(test_dataset, index_dataset, ranked_list, 1, k=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6073cd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_query_and_top_k_match(test_dataset, index_dataset, ranked_list, 2, k=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54beeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_query_and_top_k_match(test_dataset, index_dataset, ranked_list, 3, k=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5e2c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_query_and_top_k_match(test_dataset, index_dataset, ranked_list, 4, k=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885c6875",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_query_and_top_k_match(test_dataset, index_dataset, ranked_list, 5, k=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d7dd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_query_and_top_k_match(test_dataset, index_dataset, ranked_list, 6, k=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80a6743",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_query_and_top_k_match(test_dataset, index_dataset, ranked_list, 7, k=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bd6535",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_query_and_top_k_match(test_dataset, index_dataset, ranked_list, 8, k=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915b7b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_query_and_top_k_match(test_dataset, index_dataset, ranked_list, 9, k=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7176ef00",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_query_and_top_k_match(test_dataset, index_dataset, ranked_list, 10, k=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ea5805",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_query_and_top_k_match(test_dataset, index_dataset, ranked_list, 11, k=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff6525b",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_query_and_top_k_match(test_dataset, index_dataset, ranked_list, 100, k=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec80762",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_query_and_top_k_match(test_dataset, index_dataset, ranked_list, 110, k=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1986b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_query_and_top_k_match(test_dataset, index_dataset, ranked_list, 120, k=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9729169a",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_query_and_top_k_match(test_dataset, index_dataset, ranked_list, 200, k=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6454215f",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_query_and_top_k_match(test_dataset, index_dataset, ranked_list, 230, k=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c98b264",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_query_and_top_k_match(test_dataset, index_dataset, ranked_list, 250, k=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ee84bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_query_and_top_k_match(test_dataset, index_dataset, ranked_list, 300, k=14)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
